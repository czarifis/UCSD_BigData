{
 "metadata": {
  "name": "",
  "signature": "sha256:3979f3b89b0ca151dfe823f7f5dff2753737755af958db95dad0d27ebaa8a409"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's import all the important libs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!gunzip stations.pkl.gz\n",
      "import pickle\n",
      "!gunzip -c stations.pkl.gz > stations.pkl  # This command also keeps the initial gz file....\n",
      "stations=pickle.load(open('stations.pkl', 'rb'))\n",
      "stations.head()\n",
      "stations\n",
      "no_headers = pd.read_pickle('stations.pkl')\n",
      "#no_headers.columns = ['latitude', 'longitude', 'elevation', 'state', 'name', 'GSNFLAG', 'HCNFLAG', 'WMOID']\n",
      "no_headers['station'] = no_headers.index\n",
      "no_headers.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>elevation</th>\n",
        "      <th>state</th>\n",
        "      <th>name</th>\n",
        "      <th>GSNFLAG</th>\n",
        "      <th>HCNFLAG</th>\n",
        "      <th>WMOID</th>\n",
        "      <th>station</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td> 17.1167</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   10.1</td>\n",
        "      <td> NaN</td>\n",
        "      <td> ST JOHNS COOLIDGE FLD</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> ACW00011604</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td> 17.1333</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   19.2</td>\n",
        "      <td> NaN</td>\n",
        "      <td>              ST JOHNS</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td> ACW00011647</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 25.3330</td>\n",
        "      <td> 55.5170</td>\n",
        "      <td>   34.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   SHARJAH INTER. AIRP</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 41196</td>\n",
        "      <td> AE000041196</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 35.3170</td>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 3366.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>          NORTH-SALANG</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 40930</td>\n",
        "      <td> AF000040930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td> 36.7167</td>\n",
        "      <td>  3.2500</td>\n",
        "      <td>   24.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>    ALGER-DAR EL BEIDA</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 60390</td>\n",
        "      <td> AG000060390</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 9 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "             latitude  longitude  elevation state                   name  \\\n",
        "ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
        "ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
        "AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
        "AF000040930   35.3170    69.0170     3366.0   NaN           NORTH-SALANG   \n",
        "AG000060390   36.7167     3.2500       24.0   NaN     ALGER-DAR EL BEIDA   \n",
        "\n",
        "            GSNFLAG HCNFLAG  WMOID      station  \n",
        "ACW00011604     NaN     NaN    NaN  ACW00011604  \n",
        "ACW00011647     NaN     NaN    NaN  ACW00011647  \n",
        "AE000041196     GSN     NaN  41196  AE000041196  \n",
        "AF000040930     GSN     NaN  40930  AF000040930  \n",
        "AG000060390     GSN     NaN  60390  AG000060390  \n",
        "\n",
        "[5 rows x 9 columns]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile getweights.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type. \n",
      "\"\"\"\n",
      "import sys\n",
      "sys.path.append('/usr/lib/python2.6/dist-packages')\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        #try:\n",
      "            self.increment_counter('MrJob Counters','mapper-all',1)\n",
      "            elements=line.split(',')\n",
      "            if elements[0]=='station':\n",
      "                out=('header',1)\n",
      "                yield out\n",
      "            else:\n",
      "                if elements[1]=='TMAX':\n",
      "                    #if elements[2]=='1973':\n",
      "                        #stderr.write(len(filter(\"\", elements[3:])))\n",
      "                        \n",
      "                        #sys.stderr.write(', '.join(len(filter(None, elements))))\n",
      "                        #sys.stderr.write(str(len(filter(None, elements[3:]))))\n",
      "                        #sys.stderr.write(' measurements out of '+str(len(elements[3:]))+' on basestation: '+elements[0]+'\\n')\n",
      "                        out=(elements[0],(str(len(filter(None, elements[3:]))),0))\n",
      "                        yield out\n",
      "                elif elements[1]=='TMIN':\n",
      "                        out=(elements[0],(0,str(len(filter(None, elements[3:])))))\n",
      "                        yield out\n",
      "                \n",
      "                \n",
      "                #out=(elements[1],1)\n",
      "                \n",
      "        #except Exception, e:\n",
      "        #    stderr.write('Error in line:\\n'+line)\n",
      "        #    stderr.write(e)\n",
      "        #    self.increment_counter('MrJob Counters','mapper-error',1)\n",
      "        #    out=('error',1)\n",
      "        #    yield out\n",
      "\n",
      "        #finally:\n",
      "        #    yield out\n",
      "        \n",
      "        \n",
      "    def combiner(self, station, maxmin):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        #sys.stderr.write('basestation: '+station+'\\n')\n",
      "        maxs=[]\n",
      "        mins=[]\n",
      "        for x,y in maxmin:\n",
      "            #sys.stderr.write('tuple of max min for basestation: '+station+': '+str(x)+','+str(y)+'\\n')\n",
      "            maxs.append(int(x))\n",
      "            mins.append(int(y))\n",
      "            #sys.stderr.write(str(x))\n",
      "            #yield (station, 1)\n",
      "        summax = sum(maxs)\n",
      "        summin = sum(mins)\n",
      "        #sys.stderr.write('number of max measurements: '+str(summax)+' number of min measurements: '+str(summin)+'\\n')\n",
      "        yield (station,(summax,summin))\n",
      "        \n",
      "        \n",
      "\n",
      "    def reducer(self, station, maxmin):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        #sys.stderr.write('basestation: '+station+'\\n')\n",
      "        maxs=[]\n",
      "        mins=[]\n",
      "        for x,y in maxmin:\n",
      "            #sys.stderr.write('tuple of max min for basestation: '+station+': '+str(x)+','+str(y)+'\\n')\n",
      "            maxs.append(int(x))\n",
      "            mins.append(int(y))\n",
      "            #sys.stderr.write(str(x))\n",
      "            #yield (station, 1)\n",
      "        summax = sum(maxs)\n",
      "        summin = sum(mins)\n",
      "        #sys.stderr.write('number of max measurements: '+str(summax)+' number of min measurements: '+str(summin)+'\\n')\n",
      "        yield (station,(summax,summin))\n",
      "        \n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting getweights.py\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local_data='/home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv'\n",
      "!ls -l $local_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r-- 1 ubuntu ubuntu 858960 May 20 00:23 /home/ubuntu/UCSD_BigData/data/weather/ALL.head.csv\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python getweights.py $local_data > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n",
        "creating tmp directory /tmp/getweights.ubuntu.20140521.043204.686280\r\n",
        "writing to /tmp/getweights.ubuntu.20140521.043204.686280/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 999\r\n",
        "    reducer: 4\r\n",
        "writing to /tmp/getweights.ubuntu.20140521.043204.686280/step-0-mapper-sorted\r\n",
        "> sort /tmp/getweights.ubuntu.20140521.043204.686280/step-0-mapper_part-00000\r\n",
        "writing to /tmp/getweights.ubuntu.20140521.043204.686280/step-0-reducer_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  MrJob Counters:\r\n",
        "    mapper-all: 999\r\n",
        "    reducer: 8\r\n",
        "Moving /tmp/getweights.ubuntu.20140521.043204.686280/step-0-reducer_part-00000 -> /tmp/getweights.ubuntu.20140521.043204.686280/output/part-00000\r\n",
        "Streaming final output from /tmp/getweights.ubuntu.20140521.043204.686280/output\r\n",
        "removing tmp directory /tmp/getweights.ubuntu.20140521.043204.686280\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"MX000008172\"\t[15295, 14732]\r\n",
        "\"RSM00024933\"\t[5540, 0]\r\n",
        "\"USC00211063\"\t[14005, 13979]\r\n",
        "\"USC00500433\"\t[4794, 4837]\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "Creds= pickle.load(open('/home/ubuntu/Vault/Creds.pkl','rb'))\n",
      "print Creds.keys()\n",
      "print Creds['mrjob'].keys()\n",
      "pair=Creds['mrjob']\n",
      "key_id=pair['key_id']\n",
      "secret_key=pair['secret_key']\n",
      "ID=pair['ID']\n",
      "#print ID,key_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['launcher', 'mrjob']\n",
        "['key_id', 'secret_key', 's3_logs', 'ID', 's3_scratch']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<boto.emr.emrobject.JobFlow object at 0x6a35610> no_script.yoavfreund.20140516.040032.370095 j-262J0JTFJIRLO WAITING\n",
        "<boto.emr.emrobject.JobFlow object at 0x5d03cd0> no_script.yoavfreund.20140517.080731.371759 j-1RE8D7HBISOI0 WAITING\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "u'j-1RE8D7HBISOI0'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python getweights.py -r emr --emr-job-flow-id $job_flow_id hdfs:/weather/weather.csv > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "using configs in /home/ubuntu/.mrjob.conf\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "creating tmp directory /tmp/getweights.ubuntu.20140521.043208.304221\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Copying non-input files into s3://costaszarifisbucket/scratch/getweights.ubuntu.20140521.043208.304221/files/\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Adding our job to existing job flow j-1RE8D7HBISOI0\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 30.6s ago, status RUNNING: Running step (getweights.ubuntu.20140521.043208.304221: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 61.0s ago, status RUNNING: Running step (getweights.ubuntu.20140521.043208.304221: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 91.5s ago, status RUNNING: Running step (getweights.ubuntu.20140521.043208.304221: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 121.9s ago, status RUNNING: Running step (getweights.ubuntu.20140521.043208.304221: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job launched 152.4s ago, status RUNNING: Running step (getweights.ubuntu.20140521.043208.304221: Step 1 of 1)\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Job on job flow j-1RE8D7HBISOI0 failed with status WAITING: Waiting after step failed\r\n",
        "Logs are in s3://yoav.hadoop/log/j-1RE8D7HBISOI0/\r\n",
        "ec2_key_pair_file not specified, going to S3\r\n",
        "Scanning S3 logs for probable cause of failure\r\n",
        "Waiting 5.0s for S3 eventual consistency\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Attempting to terminate job...\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\r\n",
        "  File \"getweights.py\", line 84, in <module>\r\n",
        "    MRWeather.run()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 494, in run\r\n",
        "    mr_job.execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/job.py\", line 512, in execute\r\n",
        "    super(MRJob, self).execute()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 147, in execute\r\n",
        "    self.run_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/launch.py\", line 213, in run_job\r\n",
        "    self.stdout.flush()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 614, in __exit__\r\n",
        "    self.cleanup()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1010, in cleanup\r\n",
        "    super(EMRJobRunner, self).cleanup(mode=mode)\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/runner.py\", line 560, in cleanup\r\n",
        "    self._cleanup_job()\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/emr.py\", line 1084, in _cleanup_job\r\n",
        "    self._opts['ec2_key_pair_file'])\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 200, in ssh_terminate_single_job\r\n",
        "    ssh_bin, address, ec2_key_pair_file, ['hadoop', 'job', '-list']))\r\n",
        "  File \"/usr/local/lib/python2.7/dist-packages/mrjob/ssh.py\", line 82, in ssh_run\r\n",
        "    p = Popen(args, stdout=PIPE, stderr=PIPE, stdin=PIPE)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 709, in __init__\r\n",
        "    errread, errwrite)\r\n",
        "  File \"/home/ubuntu/anaconda/lib/python2.7/subprocess.py\", line 1326, in _execute_child\r\n",
        "    raise child_exception\r\n",
        "TypeError: execv() arg 2 must contain only strings\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls -al ~\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 495880\r\n",
        "drwxr-xr-x 25 ubuntu ubuntu      4096 May 21 04:10 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
        "drwxr-xr-x  3 root   root        4096 Oct  1  2012 \u001b[01;34m..\u001b[0m/\r\n",
        "drwxrwxr-x 14 ubuntu ubuntu      4096 Apr 21 23:07 \u001b[01;34manaconda\u001b[0m/\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu 507498869 Apr  9 22:01 Anaconda-1.9.2-Linux-x86_64.sh\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu      1842 May  9 04:48 apt-get.log\r\n",
        "-rw-------  1 ubuntu ubuntu     58236 May 21 04:18 .bash_eternal_history\r\n",
        "-rw-------  1 ubuntu ubuntu      9064 May 20 00:36 .bash_history\r\n",
        "-rw-r--r--  1 ubuntu ubuntu       220 Apr  3  2012 .bash_logout\r\n",
        "-rw-r--r--  1 ubuntu ubuntu      4177 Mar 27 04:37 .bashrc\r\n",
        "-rw-r--r--  1 ubuntu ubuntu      4265 Mar 27 04:36 .bashrc~\r\n",
        "-rw-r--r--  1 ubuntu ubuntu      4176 Mar 25 04:14 .bashrc-anaconda.bak\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu       120 Jan 11 01:38 .boto\r\n",
        "drwxr-xr-x  3 root   root        4096 Apr 29 19:03 \u001b[01;34m.cabal\u001b[0m/\r\n",
        "drwx------  2 ubuntu ubuntu      4096 Nov 29  2012 \u001b[01;34m.cache\u001b[0m/\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu      4096 Mar 25 04:13 \u001b[01;34m.continuum\u001b[0m/\r\n",
        "lrwxrwxrwx  1 ubuntu ubuntu        18 Apr  7 21:31 \u001b[01;36mdata\u001b[0m -> \u001b[01;34mUCSD_BigData/data/\u001b[0m/\r\n",
        "drwxrwxr-x  3 ubuntu ubuntu      4096 Mar 27 02:42 \u001b[01;34m.distlib\u001b[0m/\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu       523 May  9 04:49 easy_install.log\r\n",
        "drwx------  3 ubuntu ubuntu      4096 Jan 10 00:32 \u001b[01;34m.emacs.d\u001b[0m/\r\n",
        "drwx------  2 ubuntu ubuntu      4096 May 21 04:10 \u001b[01;34m.gnupg\u001b[0m/\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu      4096 May 21 02:05 \u001b[01;34m.ipynb_checkpoints\u001b[0m/\r\n",
        "drwxr-xr-x 10 ubuntu ubuntu      4096 Mar 31 05:24 \u001b[01;34mipython\u001b[0m/\r\n",
        "drwxrwxr-x  6 ubuntu ubuntu      4096 Apr 17 15:47 \u001b[01;34m.ipython\u001b[0m/\r\n",
        "drwxr-xr-x 10 ubuntu ubuntu      4096 Jan 10 04:16 \u001b[01;34mjinja2\u001b[0m/\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu     15403 May  7 19:36 Jobs_and_runners.ipynb\r\n",
        "-rw-------  1 ubuntu ubuntu        81 Mar 21 15:10 .lesshst\r\n",
        "drwxrwxr-x  3 ubuntu ubuntu      4096 Apr 26 19:51 \u001b[01;34mlogs\u001b[0m/\r\n",
        "drwxrwxr-x  3 ubuntu ubuntu      4096 May 21 04:31 \u001b[01;34m.matplotlib\u001b[0m/\r\n",
        "-rw-r--r--  1 ubuntu ubuntu       479 May 21 04:28 .mrjob.conf\r\n",
        "-rw-r--r--  1 ubuntu ubuntu       743 May 12 00:25 .mrjob.conf~\r\n",
        "-rw-------  1 ubuntu ubuntu         7 May 21 04:28 .nano_history\r\n",
        "drwxrwxr-x 16 ubuntu ubuntu      4096 Apr  9 01:25 \u001b[01;34mnotebooks\u001b[0m/\r\n",
        "drwxrwxr-x  5 ubuntu ubuntu      4096 Nov 29  2012 \u001b[01;34m.orange\u001b[0m/\r\n",
        "drwxrwxr-x  8 ubuntu ubuntu      4096 May  1 14:35 \u001b[01;34mpackages\u001b[0m/\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu      4096 Nov 29  2012 \u001b[01;34m.pip\u001b[0m/\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu      3454 May  9 04:46 pip.Install.log\r\n",
        "-rw-r--r--  1 ubuntu ubuntu       714 May 20 00:26 .profile\r\n",
        "drwx------  2 ubuntu ubuntu      4096 Feb 25 01:35 \u001b[01;34m.python27_compiled\u001b[0m/\r\n",
        "-rw-------  1 ubuntu ubuntu      1024 Jan 10 04:00 .rnd\r\n",
        "-rw-------  1 ubuntu ubuntu      1172 May 21 04:10 .s3cfg\r\n",
        "lrwxrwxrwx  1 ubuntu ubuntu        24 Mar 21 14:50 \u001b[01;36mscripts\u001b[0m -> \u001b[01;34mUCSD_BigData/AWS_scripts\u001b[0m/\r\n",
        "drwx------  2 ubuntu ubuntu      4096 Nov 29  2012 \u001b[01;34m.ssh\u001b[0m/\r\n",
        "-rw-r--r--  1 ubuntu ubuntu         0 Nov 29  2012 .sudo_as_admin_successful\r\n",
        "drwxr-xr-x 10 ubuntu ubuntu      4096 May 20 00:23 \u001b[01;34mUCSD_BigData\u001b[0m/\r\n",
        "drwxr-xr-x  8 ubuntu ubuntu      4096 May 11 22:57 \u001b[01;34mUCSD_BigDataYoavs\u001b[0m/\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu      4096 May 20 00:33 \u001b[01;34mVault\u001b[0m/\r\n",
        "drwx------  2 ubuntu ubuntu      4096 Mar  1 05:11 \u001b[01;34m.w3m\u001b[0m/\r\n",
        "-rw-------  1 ubuntu ubuntu       129 Jan 10 21:59 .Xauthority\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ~/.mrjob.conf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "# This is a mrjob cnfiguration file that should work \r\n",
        "# for the students in the UCSD big data class\r\n",
        "# \r\n",
        "runners:\r\n",
        "  name: give this job a name!\r\n",
        "  owner: Write your name here!\r\n",
        "  emr:\r\n",
        "    # Region to connect to S3 and EMR on (e.g. us-west-1).\r\n",
        "    aws_region: us-east-1\r\n",
        "    aws_access_key_id: AKIAIODVX66NODCCA7VQ\r\n",
        "    aws_secret_access_key: DxMPaWvXjifd97dWJ+BoApyvRtthwKvbtKxzt2n9\r\n",
        "    s3_log_uri: s3://costaszarifisbucket/logs/\r\n",
        "    s3_scratch_uri: s3://costaszarifisbucket/scratch/\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}