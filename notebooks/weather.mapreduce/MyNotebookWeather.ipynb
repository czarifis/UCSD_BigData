{
 "metadata": {
  "name": "",
  "signature": "sha256:6a5814889ad1067d7947e0509ecdc37a4fc45b469089b61b0d53e52afc8820a9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Weather processing\n",
      "\n",
      "Let's begin by loading the data we have about the stations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Let's remove stations.pkl file in case it exists and re-create it by unzip the corresponding .gz file\n",
      "## Also let's import everything\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn as sk\n",
      "import sys\n",
      "print 'pandas version: ',pd.__version__\n",
      "print 'numpy version:',np.__version__\n",
      "print 'sklearn version:',sk.__version__\n",
      "!ls -al\n",
      "!rm stations.pkl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "pandas version:  0.13.1\n",
        "numpy version: 1.8.1\n",
        "sklearn version: 0.14.1\n",
        "total 2124\r\n",
        "drwxrwxr-x  3 ubuntu ubuntu    4096 May 15 01:24 .\r\n",
        "drwxrwxr-x 14 ubuntu ubuntu    4096 May 15 00:50 ..\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu     307 May 15 00:50 coding.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    2506 May 15 00:50 Description of Assignment.ipynb\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu     723 May 15 00:50 Eigen-by-Station.sh\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu    4096 May 15 00:50 .ipynb_checkpoints\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    1408 May 15 00:50 map-year-temp.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu  114179 May 15 01:15 mrjob and EMR.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    1198 May 15 00:50 mr_weather.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    1610 May 15 00:50 mr_word_freq_count.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   38254 May 15 01:26 MyNotebookWeather.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu     698 May 15 00:50 README.txt\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    1226 May 15 00:50 reduce-year-temp.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu 1833012 May 15 01:15 stations.pkl.gz\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    5136 May 15 00:50 Statistics.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   77711 May 15 01:15 weather_MRjob.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   49211 May 15 01:27 weather_MRjob-with-utils.ipynb\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: cannot remove `stations.pkl': No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!gunzip stations.pkl.gz\n",
      "import pickle\n",
      "!gunzip -c stations.pkl.gz > stations.pkl  # This command also keeps the initial gz file....\n",
      "!ls -al\n",
      "stations=pickle.load(open('stations.pkl', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 9988\r\n",
        "drwxrwxr-x  3 ubuntu ubuntu    4096 May 16 01:22 .\r\n",
        "drwxrwxr-x 14 ubuntu ubuntu    4096 May 15 00:50 ..\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu     307 May 15 00:50 coding.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    2506 May 15 00:50 Description of Assignment.ipynb\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu     723 May 15 00:50 Eigen-by-Station.sh\r\n",
        "drwxrwxr-x  2 ubuntu ubuntu    4096 May 15 00:50 .ipynb_checkpoints\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    1408 May 15 00:50 map-year-temp.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu  114179 May 15 01:15 mrjob and EMR.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    1198 May 15 00:50 mr_weather.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu    1610 May 15 00:50 mr_word_freq_count.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   38254 May 15 01:26 MyNotebookWeather.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu     698 May 15 00:50 README.txt\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    1226 May 15 00:50 reduce-year-temp.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu 8051413 May 16 01:22 stations.pkl\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu 1833012 May 15 01:15 stations.pkl.gz\r\n",
        "-rwxrwxr-x  1 ubuntu ubuntu    5136 May 15 00:50 Statistics.py\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   77711 May 15 01:15 weather_MRjob.ipynb\r\n",
        "-rw-rw-r--  1 ubuntu ubuntu   49211 May 15 01:27 weather_MRjob-with-utils.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stations.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>elevation</th>\n",
        "      <th>state</th>\n",
        "      <th>name</th>\n",
        "      <th>GSNFLAG</th>\n",
        "      <th>HCNFLAG</th>\n",
        "      <th>WMOID</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>ACW00011604</th>\n",
        "      <td> 17.1167</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   10.1</td>\n",
        "      <td> NaN</td>\n",
        "      <td> ST JOHNS COOLIDGE FLD</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>ACW00011647</th>\n",
        "      <td> 17.1333</td>\n",
        "      <td>-61.7833</td>\n",
        "      <td>   19.2</td>\n",
        "      <td> NaN</td>\n",
        "      <td>              ST JOHNS</td>\n",
        "      <td> NaN</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AE000041196</th>\n",
        "      <td> 25.3330</td>\n",
        "      <td> 55.5170</td>\n",
        "      <td>   34.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>   SHARJAH INTER. AIRP</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 41196</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AF000040930</th>\n",
        "      <td> 35.3170</td>\n",
        "      <td> 69.0170</td>\n",
        "      <td> 3366.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>          NORTH-SALANG</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 40930</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>AG000060390</th>\n",
        "      <td> 36.7167</td>\n",
        "      <td>  3.2500</td>\n",
        "      <td>   24.0</td>\n",
        "      <td> NaN</td>\n",
        "      <td>    ALGER-DAR EL BEIDA</td>\n",
        "      <td> GSN</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 60390</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "             latitude  longitude  elevation state                   name  \\\n",
        "ACW00011604   17.1167   -61.7833       10.1   NaN  ST JOHNS COOLIDGE FLD   \n",
        "ACW00011647   17.1333   -61.7833       19.2   NaN               ST JOHNS   \n",
        "AE000041196   25.3330    55.5170       34.0   NaN    SHARJAH INTER. AIRP   \n",
        "AF000040930   35.3170    69.0170     3366.0   NaN           NORTH-SALANG   \n",
        "AG000060390   36.7167     3.2500       24.0   NaN     ALGER-DAR EL BEIDA   \n",
        "\n",
        "            GSNFLAG HCNFLAG  WMOID  \n",
        "ACW00011604     NaN     NaN    NaN  \n",
        "ACW00011647     NaN     NaN    NaN  \n",
        "AE000041196     GSN     NaN  41196  \n",
        "AF000040930     GSN     NaN  40930  \n",
        "AG000060390     GSN     NaN  60390  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Let's see if we can connect to S3\n",
      "import boto\n",
      "from boto.s3.connection import S3Connection\n",
      "from boto.s3.connection import OrdinaryCallingFormat  # this allows us to use buckets that have uppercase letters in their names...\n",
      "conn = boto.connect_s3(calling_format=OrdinaryCallingFormat())\n",
      "rs = conn.get_all_buckets()\n",
      "#print \"printing all the buckets\"\n",
      "#rs\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bucket = conn.get_bucket('Weather.GHNC')\n",
      "for key in bucket.list():\n",
      "    print key.name.encode('utf-8')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALL.csv.gz\n",
        "data-source.txt\n",
        "ghcnd-readme.txt\n",
        "ghcnd-stations.txt\n",
        "ghcnd-stations_buffered.txt\n",
        "ghcnd-version.txt\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bucket = conn.get_bucket('costaszarifisbucket')\n",
      "#for key in bucket.list():\n",
      "#    print key.name.encode('utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_weather.py\n",
      "#!/usr/bin/python\n",
      "\"\"\"\n",
      "count the number of measurements of each type\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWeather(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        self.increment_counter('MrJob Counters','mapper',1)\n",
      "        elements=line.split(',')\n",
      "        if elements[0]=='station':\n",
      "            yield('header',1)\n",
      "        else:\n",
      "            yield(elements[1],1)\n",
      "            \n",
      "    def combiner(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','combiner',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        self.increment_counter('MrJob Counters','reducer',1)\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWeather.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_weather.py\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "home_dir='/home/ubuntu/UCSD_BigData'\n",
      "sys.path.append(home_dir+'/utils')\n",
      "from find_waiting_flow import *\n",
      "from AWS_keypair_management import *\n",
      "\n",
      "AWSinst = AWS_keypair_management()\n",
      "AWSinst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# here we choose to use the second key pair\n",
      "#(Creds,bad_files) =AWSinst.Get_Working_Credentials('/home/ubuntu/Vault')\n",
      "#Creds\n",
      "pair=Creds['kozarifi']\n",
      "key_id=pair['Access_Key_Id']\n",
      "secret_key=pair['Secret_Access_Key']\n",
      "job_flow_id=find_waiting_flow(key_id,secret_key)\n",
      "job_flow_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "credentials.csv AWS creds: kozarifi AKIAIODVX66NODCCA7VQ\n",
        "an active key pair"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "'Access_Key_Id'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-24-6a19c6adc018>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Creds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kozarifi'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mkey_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Access_Key_Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0msecret_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Secret_Access_Key'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mjob_flow_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_waiting_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecret_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'Access_Key_Id'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}